{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "17ed1555cfbb96ddcf655400d6c25a9cebe961c1b69daf25bae91d698acdd2a7"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('hsh': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29I-OwCEYzW",
        "outputId": "db8b297c-a4b8-457a-b43f-7570135306c7"
      },
      "source": [
        "# Image De-blurring by Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQxN_6v6fAYB"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4KGXcVifAYC",
        "outputId": "f53c921d-7dea-438e-c7e3-c9c326393907"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from math import log10\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hNhomLifAYD"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX6pM_d0fAYD",
        "outputId": "fde97f2b-540f-4ea8-9157-fd844f90b6b0"
      },
      "source": [
        "directory_data  = './drive/MyDrive/Colab Notebooks/'\n",
        "filename_data   = 'assignment_11_data.npz'\n",
        "data            = np.load(os.path.join(directory_data, filename_data))\n",
        "\n",
        "original_train  = data['original_train']\n",
        "blur_train      = data['blur_train']\n",
        "\n",
        "original_test   = data['original_test']\n",
        "blur_test       = data['blur_test']\n",
        "\n",
        "num_data_train  = original_train.shape[0]\n",
        "num_data_test   = original_test.shape[0]\n",
        "\n",
        "print('*************************************************')\n",
        "print('size of original_train :', original_train.shape)\n",
        "print('size of blur_train :', blur_train.shape)\n",
        "print('*************************************************')\n",
        "print('size of original_test :', original_test.shape)\n",
        "print('size of blur_test :', blur_test.shape)\n",
        "print('*************************************************')\n",
        "print('number of training image :', original_train.shape[0])\n",
        "print('height of training image :', original_train.shape[1])\n",
        "print('width of training image :', original_train.shape[2])\n",
        "print('*************************************************')\n",
        "print('number of testing image :', original_test.shape[0])\n",
        "print('height of testing image :', original_test.shape[1])\n",
        "print('width of testing image :', original_test.shape[2])\n",
        "print('*************************************************')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "size of original_train : (200, 256, 256)\n",
            "size of blur_train : (200, 256, 256)\n",
            "*************************************************\n",
            "size of original_test : (100, 256, 256)\n",
            "size of blur_test : (100, 256, 256)\n",
            "*************************************************\n",
            "number of training image : 200\n",
            "height of training image : 256\n",
            "width of training image : 256\n",
            "*************************************************\n",
            "number of testing image : 100\n",
            "height of testing image : 256\n",
            "width of testing image : 256\n",
            "*************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITSvsnzOfAYE"
      },
      "source": [
        "## hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYGnGWRhfAYF"
      },
      "source": [
        "device          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "number_epoch    = 1000\n",
        "size_minibatch  = 100\n",
        "learning_rate   = 0.001\n",
        "weight_decay    = 0.000001"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBJFXe-JfAYG"
      },
      "source": [
        "## custom data loader for the PyTorch framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9QhcihPfAYG"
      },
      "source": [
        "class dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, original, blur, transform=False):\n",
        "        \n",
        "        self.original   = original\n",
        "        self.blur       = blur \n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        original    = self.original[index]\n",
        "        blur        = self.blur[index]\n",
        "        \n",
        "        original    = torch.FloatTensor(original).unsqueeze(dim=0)\n",
        "        blur        = torch.FloatTensor(blur).unsqueeze(dim=0)\n",
        "\n",
        "        if self.transform:\n",
        "\n",
        "            crop_size = [64, 64]\n",
        "            # random crop\n",
        "            top         = random.randint(0, original.shape[1] - crop_size[0])\n",
        "            left        = random.randint(0, original.shape[2] - crop_size[1])\n",
        "            original    = transforms.functional.crop(original, top, left, crop_size[0], crop_size[1])\n",
        "            blur        = transforms.functional.crop(blur, top, left, crop_size[0], crop_size[1])\n",
        "            \n",
        "            # random horizontal flip\n",
        "            if random.random() > 0.5: \n",
        "                original = transforms.functional.hflip(original)\n",
        "                blur = transforms.functional.hflip(blur)\n",
        "\n",
        "            # random vertical flip\n",
        "            if random.random() > 0.5: \n",
        "                original = transforms.functional.vflip(original)\n",
        "                blur = transforms.functional.vflip(blur)\n",
        "\n",
        "        return (original, blur)\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.original.shape[0]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGdRB24hfAYH"
      },
      "source": [
        "## construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82-PEmPhfAYH"
      },
      "source": [
        "dataset_train_transform = dataset(original_train, blur_train, transform=True)\n",
        "dataset_train           = dataset(original_train, blur_train)\n",
        "dataset_test            = dataset(original_test, blur_test)\n",
        "\n",
        "dataloader_train_transform  = DataLoader(dataset_train_transform, batch_size=size_minibatch, shuffle=True, drop_last=True)\n",
        "dataloader_train            = DataLoader(dataset_train, batch_size=1, shuffle=False, drop_last=True)\n",
        "dataloader_test             = DataLoader(dataset_test, batch_size=1, shuffle=False, drop_last=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqHrXPmHfAYI"
      },
      "source": [
        "## shape of the data when using the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LhGEFFWfAYI",
        "outputId": "2019cd2b-00f8-4fe1-f016-725ee28bbd52"
      },
      "source": [
        "(original_train, blur_train)  = dataset_train[0]\n",
        "(original_test, blur_test)    = dataset_test[0]\n",
        "(original_train_transform, blur_train_transform)  = dataset_train_transform[0]\n",
        "print('*******************************************************************')\n",
        "print('shape of the original in the training dataset:', original_train.shape)\n",
        "print('shape of the blur in the training dataset:', blur_train.shape)\n",
        "print('*******************************************************************')\n",
        "print('shape of the original in the testing dataset:', original_test.shape)\n",
        "print('shape of the blur in the testing dataset:', blur_test.shape)\n",
        "print('*******************************************************************')\n",
        "print('shape of the original in the training transform dataset:', original_train_transform.shape)\n",
        "print('shape of the blur in the training transform dataset:', blur_train_transform.shape)\n",
        "print('*******************************************************************')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************************************************************\n",
            "shape of the original in the training dataset: torch.Size([1, 256, 256])\n",
            "shape of the blur in the training dataset: torch.Size([1, 256, 256])\n",
            "*******************************************************************\n",
            "shape of the original in the testing dataset: torch.Size([1, 256, 256])\n",
            "shape of the blur in the testing dataset: torch.Size([1, 256, 256])\n",
            "*******************************************************************\n",
            "shape of the original in the training transform dataset: torch.Size([1, 64, 64])\n",
            "shape of the blur in the training transform dataset: torch.Size([1, 64, 64])\n",
            "*******************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGcSZubBfAYI"
      },
      "source": [
        "## class for the neural network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISorewl8fAYI"
      },
      "source": [
        "class Network(nn.Module): \n",
        "\n",
        "\tdef __init__(self, in_channel=1, out_channel=1, dim_feature=64, dim_code=8, threshold_ReLU=0.01):\n",
        "        \n",
        "\t\tsuper(Network, self).__init__()\n",
        "\n",
        "\t\tself.in_channel \t= in_channel\n",
        "\t\tself.out_channel\t= out_channel\n",
        "\t\tself.dim_feature\t= dim_feature\n",
        "\t\t\n",
        "\t\tself.conv_encode1\t= nn.Conv2d(in_channel , dim_feature * 1, kernel_size=3, stride=2, padding=1, bias=True)\n",
        "\t\tself.conv_encode2\t= nn.Conv2d(dim_feature * 1, dim_feature * 2, kernel_size=3, stride=2, padding=1, bias=True)\n",
        "\t\tself.conv_encode3\t= nn.Conv2d(dim_feature * 2, dim_feature * 4, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\n",
        "\t\tself.conv_decode2 \t= nn.Conv2d(dim_feature * 4, dim_feature * 2, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\t\tself.conv_decode1 \t= nn.Conv2d(dim_feature * 2, dim_feature * 1, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "\t\tself.conv_out \t\t= nn.Conv2d(dim_feature * 1, out_channel,\tkernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "\t\tself.ebn1\t\t\t= nn.BatchNorm2d(dim_feature * 1)\n",
        "\t\tself.ebn2\t\t\t= nn.BatchNorm2d(dim_feature * 2)\n",
        "\t\tself.ebn3\t\t\t= nn.BatchNorm2d(dim_feature * 4)\n",
        "\t\tself.dbn2\t\t\t= nn.BatchNorm2d(dim_feature * 2)\n",
        "\t\tself.dbn1\t\t\t= nn.BatchNorm2d(dim_feature * 1)\n",
        "\n",
        "\t\tself.activation\t\t= nn.LeakyReLU(threshold_ReLU, inplace=True)\n",
        "\t\tself.activation_out\t= nn.MaxPool2d(kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "\t\t# *********************************************************************\n",
        "\t\t# forward propagation\n",
        "\t\t# *********************************************************************\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\tx1  = self.conv_encode1(x)\n",
        "\t\teb1 = self.ebn1(x1)\n",
        "\t\te1  = self.activation(eb1)\n",
        "\t\t\n",
        "\t\tx2  = self.conv_encode2(e1)\n",
        "\t\teb2 = self.ebn2(x2)\n",
        "\t\te2  = self.activation(eb2)\n",
        "\t\t\n",
        "\t\tx3  = self.conv_encode3(e2)\n",
        "\t\teb3 = self.ebn3(x3)\n",
        "\t\te3  = self.activation(eb3)\n",
        "\t\t\n",
        "\t\ty2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)(e3)\n",
        "\t\ty2  = self.conv_decode2(y2)\n",
        "\t\tdb2 = self.dbn2(y2)\n",
        "\t\td2  = self.activation(db2)\n",
        "\n",
        "\t\ty1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)(d2)\n",
        "\t\ty1  = self.conv_decode1(y1)\n",
        "\t\tdb1 = self.dbn1(y1)\n",
        "\t\td1  = self.activation(db1)\n",
        "\t\t\n",
        "\t\ty1  = self.conv_out(d1)\n",
        "\t\ty = self.activation_out(y1)\n",
        "\n",
        "\t\treturn y\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpinzm0pfAYJ"
      },
      "source": [
        "## build network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GeTcxC2fAYJ"
      },
      "source": [
        "model       = Network().to(device)\n",
        "optimizer   = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx3piDDqfAYJ"
      },
      "source": [
        "## compute the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-pTtKQnfAYJ"
      },
      "source": [
        "def compute_prediction(model, input):\n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    #\n",
        "    prediction = model(input)\n",
        "    # \n",
        "    # ==================================================\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq_S4CRifAYK"
      },
      "source": [
        "## compute the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNvnsd43fAYK"
      },
      "source": [
        "def compute_loss(prediction, label):\n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    #\n",
        "    criterion   = nn.MSELoss()\n",
        "    # \n",
        "    # ==================================================\n",
        "    loss        = criterion(prediction, label)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwlnccwyfAYK"
      },
      "source": [
        "## compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U44tYjy2fAYK"
      },
      "source": [
        "def compute_accuracy(prediction, label):\n",
        "\n",
        "    prediction  = prediction.squeeze(axis=1)\n",
        "    label       = label.squeeze(axis=1)\n",
        "    mse_loss    = torch.mean((prediction - label) ** 2)\n",
        "\n",
        "    if mse_loss == 0.0:\n",
        "        psnr = 100\n",
        "    else:\n",
        "        psnr = 10 * torch.log10(1 / mse_loss)\n",
        "\n",
        "    psnr = psnr.item()\n",
        "    \n",
        "    return psnr"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCO_wlNjfAYK"
      },
      "source": [
        "## variables for the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aez-wV6YfAYK"
      },
      "source": [
        "loss_mean_train     = np.zeros(number_epoch)\n",
        "loss_std_train      = np.zeros(number_epoch)\n",
        "accuracy_mean_train = np.zeros(number_epoch)\n",
        "accuracy_std_train  = np.zeros(number_epoch)\n",
        "\n",
        "loss_mean_test      = np.zeros(number_epoch)\n",
        "loss_std_test       = np.zeros(number_epoch)\n",
        "accuracy_mean_test  = np.zeros(number_epoch)\n",
        "accuracy_std_test   = np.zeros(number_epoch)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFwhIqu8fAYL"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBkVXPPMfAYL"
      },
      "source": [
        "def train(model, dataloader):\n",
        "\n",
        "    loss_epoch      = []\n",
        "    accuracy_epoch  = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for index_batch, (original, blur) in enumerate(dataloader):\n",
        "\n",
        "        original    = original.to(device)\n",
        "        blur        = blur.to(device)\n",
        "        \n",
        "        prediction  = compute_prediction(model, blur)\n",
        "        loss        = compute_loss(prediction, original)\n",
        "        accuracy    = compute_accuracy(prediction, original)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch.append(loss.item())\n",
        "        accuracy_epoch.append(accuracy)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "\n",
        "    accuracy_mean_epoch = np.mean(accuracy_epoch)\n",
        "    accuracy_std_epoch  = np.std(accuracy_epoch)\n",
        "\n",
        "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    accuracy    = {'mean' : accuracy_mean_epoch, 'std' : accuracy_std_epoch}\n",
        "\n",
        "    return (loss, accuracy)    \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wjaRxhhfAYL"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBwenV6UfAYL"
      },
      "source": [
        "def test(model, dataloader):\n",
        "\n",
        "    loss_epoch      = []\n",
        "    accuracy_epoch  = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for index_batch, (original, blur) in enumerate(dataloader):\n",
        "\n",
        "        original    = original.to(device)\n",
        "        blur        = blur.to(device)\n",
        "        \n",
        "        prediction  = compute_prediction(model, blur)\n",
        "        loss        = compute_loss(prediction, original)\n",
        "        accuracy    = compute_accuracy(prediction, original)\n",
        "\n",
        "        loss_epoch.append(loss.item())\n",
        "        accuracy_epoch.append(accuracy)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "\n",
        "    accuracy_mean_epoch = np.mean(accuracy_epoch)\n",
        "    accuracy_std_epoch  = np.std(accuracy_epoch)\n",
        "\n",
        "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    accuracy    = {'mean' : accuracy_mean_epoch, 'std' : accuracy_std_epoch}\n",
        "\n",
        "    return (loss, accuracy)    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lgctXQAfAYL"
      },
      "source": [
        "## train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKl6NakyfAYL",
        "outputId": "78f02168-24fa-4083-ce8e-c85eb2496a9b"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_train, accuracy_train) = train(model, dataloader_train_transform)\n",
        "\n",
        "    loss_mean_train[i]      = loss_train['mean']\n",
        "    loss_std_train[i]       = loss_train['std']\n",
        "\n",
        "    accuracy_mean_train[i]  = accuracy_train['mean']\n",
        "    accuracy_std_train[i]   = accuracy_train['std']\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_test, accuracy_test) = test(model, dataloader_test)\n",
        "\n",
        "    loss_mean_test[i]      = loss_test['mean']\n",
        "    loss_std_test[i]       = loss_test['std']\n",
        "\n",
        "    accuracy_mean_test[i]  = accuracy_test['mean']\n",
        "    accuracy_std_test[i]   = accuracy_test['std']"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [49:36<00:00,  2.98s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpVFoTnQfAYM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJJKH6W3fAYM"
      },
      "source": [
        "# functions for visualizing the results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgRhYm6LfAYM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLFVwklQfAYM"
      },
      "source": [
        "## plot curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecn5vJlUfAYM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H3rGmlZfAYM"
      },
      "source": [
        "def plot_data_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    size_col = 1.5\n",
        "    size_row = 1.5\n",
        "\n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * size_col, nRow * size_row))\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyXtMgS-fAYM"
      },
      "source": [
        "def plot_data_tensor_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    size_col = 1.5\n",
        "    size_row = 1.5\n",
        "\n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * size_col, nRow * size_row))\n",
        "\n",
        "    data = data.detach().cpu().squeeze(axis=1)\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYivTNuyfAYM"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWIFojp4fAYN"
      },
      "source": [
        "def print_curve(data, index):\n",
        "    \n",
        "    for i in range(len(index)):\n",
        "\n",
        "        idx = index[i]\n",
        "        val = data[idx]\n",
        "\n",
        "        print('index = %2d, value = %12.10f' % (idx, val))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kx6TXTmfAYN"
      },
      "source": [
        "def get_data_last(data, index_start):\n",
        "\n",
        "    data_last = data[index_start:]\n",
        "\n",
        "    return data_last"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQthefMJfAYN"
      },
      "source": [
        "def get_max_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.max()\n",
        "\n",
        "    return value"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyrBRIqSfAYN"
      },
      "source": [
        "def get_min_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.min()\n",
        "\n",
        "    return value"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADErypFCfAYN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2TVz7AYfAYN"
      },
      "source": [
        "# functions for presenting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN3mmwOpfAYN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxxCIEtffAYO"
      },
      "source": [
        "def function_result_01():\n",
        "\n",
        "    print('[plot examples of the training original images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    data_train, _   = dataset_train[index_data]\n",
        "    data_train      = data_train[0]\n",
        "    \n",
        "    plot_data_grid(data_train, index_data, nRow, nCol)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NBh2-edfAYO"
      },
      "source": [
        "def function_result_02():\n",
        "\n",
        "    print('[plot examples of the training blur images]')\n",
        "    print('') \n",
        "    \n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    _, data_train   = dataset_train[index_data]\n",
        "    data_train      = data_train[0]\n",
        "    \n",
        "    plot_data_grid(data_train, index_data, nRow, nCol)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGr5Csa9fAYO"
      },
      "source": [
        "def function_result_03():\n",
        "\n",
        "    print('[plot examples of the training de-blurring results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data          = np.arange(0, nRow * nCol)\n",
        "    _, data_train       = dataset_train[index_data] \n",
        "    data_train          = data_train[0].unsqueeze(dim=1).to(device)\n",
        "    prediction_train    = compute_prediction(model, data_train)\n",
        "    \n",
        "    plot_data_tensor_grid(prediction_train, index_data, nRow, nCol)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMo1pZE9fAYO"
      },
      "source": [
        "def function_result_04():\n",
        "\n",
        "    print('[plot examples of the testing original images]')\n",
        "    print('') \n",
        "    \n",
        "    nRow = 8 \n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    data_test, _    = dataset_test[index_data]\n",
        "    data_test       = data_test[0]\n",
        "    \n",
        "    plot_data_grid(data_test, index_data, nRow, nCol)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UQqXpQbfAYO"
      },
      "source": [
        "def function_result_05():\n",
        "\n",
        "    print('[plot examples of the testing blur images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    _, data_test    = dataset_test[index_data]\n",
        "    data_test       = data_test[0]\n",
        "    \n",
        "    plot_data_grid(data_test, index_data, nRow, nCol)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRmcQ_6ofAYO"
      },
      "source": [
        "def function_result_06():\n",
        "\n",
        "    print('[plot examples of the testing de-blurring results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 8\n",
        "    nCol = 6\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    _, data_test    = dataset_test[index_data]\n",
        "    data_test       = data_test[0].unsqueeze(dim=1).to(device)\n",
        "    prediction_test = compute_prediction(model, data_test)\n",
        "    \n",
        "    plot_data_tensor_grid(prediction_test, index_data, nRow, nCol)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZGiOwJ8fAYO"
      },
      "source": [
        "def function_result_07():\n",
        "\n",
        "    print('[plot the training loss]')\n",
        "    print('') \n",
        "\n",
        "    plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'loss (training)')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iveIq9IVfAYO"
      },
      "source": [
        "def function_result_08():\n",
        "\n",
        "    print('[plot the training accuracy]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(accuracy_mean_train, accuracy_std_train, 'epoch', 'accuracy', 'accuracy (training)')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvtXiyK9fAYP"
      },
      "source": [
        "def function_result_09():\n",
        "    \n",
        "    print('[plot the testing loss]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'loss (testing)')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKm84lvsfAYP"
      },
      "source": [
        "def function_result_10():\n",
        "    \n",
        "    print('[plot the testing accuracy]') \n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(accuracy_mean_test, accuracy_std_test, 'epoch', 'accuracy', 'accuracy (testing)')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnvKyMLtfAYP"
      },
      "source": [
        "def function_result_11():\n",
        "    \n",
        "    print('[print the training loss at the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    data_last   = get_data_last(loss_mean_train, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMLjWUCRfAYP"
      },
      "source": [
        "def function_result_12():\n",
        "    \n",
        "    print('[print the training accuracy at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last   = get_data_last(accuracy_mean_train, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nckMpHnNfAYP"
      },
      "source": [
        "def function_result_13():\n",
        "    \n",
        "    print('[print the testing loss at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last   = get_data_last(loss_mean_test, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPUAZegFfAYP"
      },
      "source": [
        "def function_result_14():\n",
        "    \n",
        "    print('[print the testing accuracy at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last   = get_data_last(accuracy_mean_test, -10)\n",
        "    index       = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIqun3LvfAYP"
      },
      "source": [
        "def function_result_15():\n",
        "    \n",
        "    print('[print the best training accuracy within the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    value = get_max_last_range(accuracy_mean_train, -10)\n",
        "    print('best training accuracy = %12.10f' % (value))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXZXyLZ_fAYP"
      },
      "source": [
        "def function_result_16():\n",
        "    \n",
        "    print('[print the best testing accuracy within the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    value = get_max_last_range(accuracy_mean_test, -10)\n",
        "    print('best testing accuracy = %12.10f' % (value))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z4zgWW5fAYQ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWG5_JzlfAYQ"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47wdEzv8fAYQ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "Amftgj5JfAYQ",
        "outputId": "130e4401-5e99-4ddd-ec56-41f8110c8087"
      },
      "source": [
        "number_result = 16\n",
        "\n",
        "for i in range(number_result):\n",
        "\n",
        "    title           = '# RESULT # {:02d}'.format(i+1) \n",
        "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
        "\n",
        "    print('') \n",
        "    print('################################################################################')\n",
        "    print('#') \n",
        "    print(title)\n",
        "    print('#') \n",
        "    print('################################################################################')\n",
        "    print('') \n",
        "\n",
        "    eval(name_function)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "################################################################################\n",
            "#\n",
            "# RESULT # 01\n",
            "#\n",
            "################################################################################\n",
            "\n",
            "[plot examples of the training original images]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-4c6785a1fe45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-3103af572841>\u001b[0m in \u001b[0;36mfunction_result_01\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnRow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mindex_data\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnRow\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnCol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata_train\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOK8thB6fAYQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}